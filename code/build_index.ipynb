{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building an index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "\n",
    "HTML('''<script>\n",
    "code_show=true; \n",
    "function code_toggle() {\n",
    " if (code_show){\n",
    " $('div.input').hide();\n",
    " } else {\n",
    " $('div.input').show();\n",
    " }\n",
    " code_show = !code_show\n",
    "} \n",
    "$( document ).ready(code_toggle);\n",
    "</script>\n",
    "<form action=\"javascript:code_toggle()\"><input type=\"submit\" value=\"Click here to toggle on/off the raw code.\"></form>''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "from math import log10\n",
    "import re\n",
    "\n",
    "#import nltk\n",
    "#nltk.download('punkt')\n",
    "#nltk.download('stopwords')\n",
    "\n",
    "import pandas as pd\n",
    "from numpy import arange\n",
    "from nltk.util import ngrams    \n",
    "from nltk.corpus import stopwords\n",
    "from nltk import FreqDist, word_tokenize, stem\n",
    "from IPython.display import Markdown, display, HTML\n",
    "\n",
    "%matplotlib inline\n",
    "default_stopwords = set(stopwords.words('portuguese'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_spread_words(words, delim):\n",
    "\n",
    "    \"\"\" Split then spread alpha word with certain delimiters.\n",
    "\n",
    "    Split words with alphabetical characters that have certain \n",
    "    delimiters then spread the resulting words across the corpus.\n",
    "\n",
    "    :param list corpus: list of words.\n",
    "    :param str delim: target delimiter.\n",
    "\n",
    "    :return: updated list of words \n",
    "\n",
    "    :rtype: list\n",
    "    \"\"\"\n",
    "    \n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        if any(c.isalnum() for c in word):\n",
    "            new_words.extend(word.split(delim))\n",
    "        else:\n",
    "            new_words.append(word)\n",
    "\n",
    "    return new_words\n",
    "\n",
    "\n",
    "def melt_merge_zipf_dfs(df_orig, df_stem, data_grain):\n",
    "\n",
    "    \"\"\" Melt then merge zipf stats dfs with and without stemming.\n",
    "\n",
    "    Melt two dfs containing zipf statistics generated with and\n",
    "    without stemming and merge both into a single dataframe.\n",
    "    \n",
    "    :param pandas.core.frame.DataFrame df_orig: zipf df without stemming.\n",
    "    :param pandas.core.frame.DataFrame dif_stem: zipf df with stemming\n",
    "    :param str data_gram: name of the n-gram (e.g bigram).\n",
    "\n",
    "    :return: resulting df containing both given dfs. \n",
    "\n",
    "    :rtype: pandas.core.frame.DataFrame\n",
    "    \"\"\"\n",
    "    \n",
    "    melt_df_orig = df_orig.melt(id_vars=[data_grain, 'Freq.','ln(Pr)'], var_name = \"ranking\",\n",
    "                          value_vars=['ln(r)', 'ln(pred_r)'])\n",
    "    melt_df_orig[\"stemming\"] = \"no_stemming\"\n",
    "    \n",
    "    melt_df_stem = df_stem.melt(id_vars=[data_grain, 'Freq.','ln(Pr)'], var_name = \"ranking\",\n",
    "                               value_vars=['ln(r)', 'ln(pred_r)'])\n",
    "    melt_df_stem[\"stemming\"] = \"stemming\"\n",
    "\n",
    "\n",
    "    melt_df = pd.concat([melt_df_orig, melt_df_stem])\n",
    "\n",
    "    return melt_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>subtitle</th>\n",
       "      <th>author</th>\n",
       "      <th>date</th>\n",
       "      <th>section</th>\n",
       "      <th>text</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>“A sociedade foi Rubens Paiva  não os facínora...</td>\n",
       "      <td>A decisão da juíza que proíbe as Forças Armada...</td>\n",
       "      <td>F. M.</td>\n",
       "      <td>30/03/2019 00:11:08</td>\n",
       "      <td>Brasil</td>\n",
       "      <td>A juíza federal Ivani Silva da Luz  de Brasíli...</td>\n",
       "      <td>https://brasil.elpais.com/brasil/2019/03/26/po...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Justiça suspende decisão que proibia Forças Ar...</td>\n",
       "      <td>Liminar havia sido concedida na sexta-feira a ...</td>\n",
       "      <td>Marina Rossi</td>\n",
       "      <td>30/03/2019 16:17:59</td>\n",
       "      <td>Brasil</td>\n",
       "      <td>Menos de 24 horas depois de a juíza federal Iv...</td>\n",
       "      <td>https://brasil.elpais.com/brasil/2019/03/30/po...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Governo Bolsonaro prega “negacionismo históric...</td>\n",
       "      <td>Marcos Napolitano  professor da USP  diz que o...</td>\n",
       "      <td>Regiane Oliveira</td>\n",
       "      <td>04/04/2019 22:37:48</td>\n",
       "      <td>Brasil</td>\n",
       "      <td>Quando  determinou que  de 31 de março 1964  u...</td>\n",
       "      <td>https://brasil.elpais.com/brasil/2019/04/05/po...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Quando os pais de Gabo perceberam que tinham u...</td>\n",
       "      <td>Gustavo Tatis percorre o universo de García Má...</td>\n",
       "      <td>Jesús Ruiz Mantilla</td>\n",
       "      <td>07/03/2019 16:38:56</td>\n",
       "      <td>Cultura</td>\n",
       "      <td>Quando  era pequeno   Luisa e  Gabriel se preo...</td>\n",
       "      <td>https://brasil.elpais.com/brasil/2019/03/06/cu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Rádios canadenses banem músicas de Michael Jac...</td>\n",
       "      <td>Quebec Cogeco Media toma a decisão após queixa...</td>\n",
       "      <td>Jaime Porras Ferreyra</td>\n",
       "      <td>07/03/2019 16:12:37</td>\n",
       "      <td>Cultura</td>\n",
       "      <td>Desde a manhã da última segunda-feira     e   ...</td>\n",
       "      <td>https://brasil.elpais.com/brasil/2019/03/06/cu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  “A sociedade foi Rubens Paiva  não os facínora...   \n",
       "1  Justiça suspende decisão que proibia Forças Ar...   \n",
       "2  Governo Bolsonaro prega “negacionismo históric...   \n",
       "3  Quando os pais de Gabo perceberam que tinham u...   \n",
       "4  Rádios canadenses banem músicas de Michael Jac...   \n",
       "\n",
       "                                            subtitle                 author  \\\n",
       "0  A decisão da juíza que proíbe as Forças Armada...                  F. M.   \n",
       "1  Liminar havia sido concedida na sexta-feira a ...           Marina Rossi   \n",
       "2  Marcos Napolitano  professor da USP  diz que o...       Regiane Oliveira   \n",
       "3  Gustavo Tatis percorre o universo de García Má...    Jesús Ruiz Mantilla   \n",
       "4  Quebec Cogeco Media toma a decisão após queixa...  Jaime Porras Ferreyra   \n",
       "\n",
       "                  date  section  \\\n",
       "0  30/03/2019 00:11:08   Brasil   \n",
       "1  30/03/2019 16:17:59   Brasil   \n",
       "2  04/04/2019 22:37:48   Brasil   \n",
       "3  07/03/2019 16:38:56  Cultura   \n",
       "4  07/03/2019 16:12:37  Cultura   \n",
       "\n",
       "                                                text  \\\n",
       "0  A juíza federal Ivani Silva da Luz  de Brasíli...   \n",
       "1  Menos de 24 horas depois de a juíza federal Iv...   \n",
       "2  Quando  determinou que  de 31 de março 1964  u...   \n",
       "3  Quando  era pequeno   Luisa e  Gabriel se preo...   \n",
       "4  Desde a manhã da última segunda-feira     e   ...   \n",
       "\n",
       "                                                 url  \n",
       "0  https://brasil.elpais.com/brasil/2019/03/26/po...  \n",
       "1  https://brasil.elpais.com/brasil/2019/03/30/po...  \n",
       "2  https://brasil.elpais.com/brasil/2019/04/05/po...  \n",
       "3  https://brasil.elpais.com/brasil/2019/03/06/cu...  \n",
       "4  https://brasil.elpais.com/brasil/2019/03/06/cu...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"../output/results.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize and Filter text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"words\"] = data[\"text\"].apply(lambda x: word_tokenize(x))\n",
    "\n",
    "# Remove words that don't have at least one alphabetical character \n",
    "data[\"words\"] = data[\"words\"].apply(lambda words: list((word for word in words if any(c.isalnum() for c in word))))\n",
    "\n",
    "# Remove hyphen at end of word\n",
    "data[\"words\"] = data[\"words\"].apply(lambda words: list(word[:-1] if word[-1] == '-' else word for word in words))\n",
    "\n",
    "# Split words joined by en dash\n",
    "data[\"words\"] = data[\"words\"].apply(lambda words: list(word for line in words for word in line.split('–')))\n",
    "# different encoding \n",
    "data[\"words\"] = data[\"words\"].apply(lambda words: list(word for line in words for word in line.split('—')))\n",
    "\n",
    "# Split words joined by dot if they are alphabetical\n",
    "data[\"words\"] = data[\"words\"].apply(lambda words: split_spread_words(words, '.'))\n",
    "\n",
    "# Remove lone punctuation from the splits\n",
    "data[\"words\"] = data[\"words\"].apply(lambda words: list(word for word in words if any(c.isalnum() for c in word)))\n",
    "\n",
    "# Remove stopwords\n",
    "data[\"words\"] = data[\"words\"].apply(lambda words: list(word for word in words if word.lower() not in default_stopwords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>subtitle</th>\n",
       "      <th>author</th>\n",
       "      <th>date</th>\n",
       "      <th>section</th>\n",
       "      <th>text</th>\n",
       "      <th>url</th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>“A sociedade foi Rubens Paiva  não os facínora...</td>\n",
       "      <td>A decisão da juíza que proíbe as Forças Armada...</td>\n",
       "      <td>F. M.</td>\n",
       "      <td>30/03/2019 00:11:08</td>\n",
       "      <td>Brasil</td>\n",
       "      <td>A juíza federal Ivani Silva da Luz  de Brasíli...</td>\n",
       "      <td>https://brasil.elpais.com/brasil/2019/03/26/po...</td>\n",
       "      <td>[juíza, federal, Ivani, Silva, Luz, Brasília, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Justiça suspende decisão que proibia Forças Ar...</td>\n",
       "      <td>Liminar havia sido concedida na sexta-feira a ...</td>\n",
       "      <td>Marina Rossi</td>\n",
       "      <td>30/03/2019 16:17:59</td>\n",
       "      <td>Brasil</td>\n",
       "      <td>Menos de 24 horas depois de a juíza federal Iv...</td>\n",
       "      <td>https://brasil.elpais.com/brasil/2019/03/30/po...</td>\n",
       "      <td>[Menos, 24, horas, juíza, federal, Ivani, Silv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Governo Bolsonaro prega “negacionismo históric...</td>\n",
       "      <td>Marcos Napolitano  professor da USP  diz que o...</td>\n",
       "      <td>Regiane Oliveira</td>\n",
       "      <td>04/04/2019 22:37:48</td>\n",
       "      <td>Brasil</td>\n",
       "      <td>Quando  determinou que  de 31 de março 1964  u...</td>\n",
       "      <td>https://brasil.elpais.com/brasil/2019/04/05/po...</td>\n",
       "      <td>[determinou, 31, março, 1964, estratégia, polê...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Quando os pais de Gabo perceberam que tinham u...</td>\n",
       "      <td>Gustavo Tatis percorre o universo de García Má...</td>\n",
       "      <td>Jesús Ruiz Mantilla</td>\n",
       "      <td>07/03/2019 16:38:56</td>\n",
       "      <td>Cultura</td>\n",
       "      <td>Quando  era pequeno   Luisa e  Gabriel se preo...</td>\n",
       "      <td>https://brasil.elpais.com/brasil/2019/03/06/cu...</td>\n",
       "      <td>[pequeno, Luisa, Gabriel, preocupavam, menino,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Rádios canadenses banem músicas de Michael Jac...</td>\n",
       "      <td>Quebec Cogeco Media toma a decisão após queixa...</td>\n",
       "      <td>Jaime Porras Ferreyra</td>\n",
       "      <td>07/03/2019 16:12:37</td>\n",
       "      <td>Cultura</td>\n",
       "      <td>Desde a manhã da última segunda-feira     e   ...</td>\n",
       "      <td>https://brasil.elpais.com/brasil/2019/03/06/cu...</td>\n",
       "      <td>[Desde, manhã, última, segunda-feira, sucessos...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  “A sociedade foi Rubens Paiva  não os facínora...   \n",
       "1  Justiça suspende decisão que proibia Forças Ar...   \n",
       "2  Governo Bolsonaro prega “negacionismo históric...   \n",
       "3  Quando os pais de Gabo perceberam que tinham u...   \n",
       "4  Rádios canadenses banem músicas de Michael Jac...   \n",
       "\n",
       "                                            subtitle                 author  \\\n",
       "0  A decisão da juíza que proíbe as Forças Armada...                  F. M.   \n",
       "1  Liminar havia sido concedida na sexta-feira a ...           Marina Rossi   \n",
       "2  Marcos Napolitano  professor da USP  diz que o...       Regiane Oliveira   \n",
       "3  Gustavo Tatis percorre o universo de García Má...    Jesús Ruiz Mantilla   \n",
       "4  Quebec Cogeco Media toma a decisão após queixa...  Jaime Porras Ferreyra   \n",
       "\n",
       "                  date  section  \\\n",
       "0  30/03/2019 00:11:08   Brasil   \n",
       "1  30/03/2019 16:17:59   Brasil   \n",
       "2  04/04/2019 22:37:48   Brasil   \n",
       "3  07/03/2019 16:38:56  Cultura   \n",
       "4  07/03/2019 16:12:37  Cultura   \n",
       "\n",
       "                                                text  \\\n",
       "0  A juíza federal Ivani Silva da Luz  de Brasíli...   \n",
       "1  Menos de 24 horas depois de a juíza federal Iv...   \n",
       "2  Quando  determinou que  de 31 de março 1964  u...   \n",
       "3  Quando  era pequeno   Luisa e  Gabriel se preo...   \n",
       "4  Desde a manhã da última segunda-feira     e   ...   \n",
       "\n",
       "                                                 url  \\\n",
       "0  https://brasil.elpais.com/brasil/2019/03/26/po...   \n",
       "1  https://brasil.elpais.com/brasil/2019/03/30/po...   \n",
       "2  https://brasil.elpais.com/brasil/2019/04/05/po...   \n",
       "3  https://brasil.elpais.com/brasil/2019/03/06/cu...   \n",
       "4  https://brasil.elpais.com/brasil/2019/03/06/cu...   \n",
       "\n",
       "                                               words  \n",
       "0  [juíza, federal, Ivani, Silva, Luz, Brasília, ...  \n",
       "1  [Menos, 24, horas, juíza, federal, Ivani, Silv...  \n",
       "2  [determinou, 31, março, 1964, estratégia, polê...  \n",
       "3  [pequeno, Luisa, Gabriel, preocupavam, menino,...  \n",
       "4  [Desde, manhã, última, segunda-feira, sucessos...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inverted Index with Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "inverted_index = {} \n",
    "for doc_id, text in enumerate(data[\"words\"]):\n",
    "    fdist = FreqDist(text)\n",
    "    for word in fdist:\n",
    "        freq = fdist[word]\n",
    "        if word not in inverted_index:\n",
    "            inverted_index[word] = []\n",
    "        \n",
    "        inverted_index[word].append((doc_id,freq))           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "***"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### Resulting Inverted Index"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>word</th>\n",
       "      <th>doc_id:freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>criativo</td>\n",
       "      <td>[(35, 2), (150, 1)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>intensa</td>\n",
       "      <td>[(42, 1), (131, 1), (196, 1), (207, 1), (216, 1)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mude</td>\n",
       "      <td>[(77, 1), (221, 1), (242, 1)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>apaixonou</td>\n",
       "      <td>[(194, 1)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>880</td>\n",
       "      <td>[(183, 1)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Kirchner</td>\n",
       "      <td>[(95, 1), (168, 1)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>levá-las</td>\n",
       "      <td>[(248, 1)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>antigo</td>\n",
       "      <td>[(36, 1), (74, 1), (114, 1), (167, 1), (173, 1), (216, 1), (237, 1), (239, 1)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>relaxamento</td>\n",
       "      <td>[(242, 1)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Vasco</td>\n",
       "      <td>[(49, 3), (75, 3), (119, 1)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>irresponsável</td>\n",
       "      <td>[(225, 1), (239, 1)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>lucro</td>\n",
       "      <td>[(27, 1), (54, 1), (75, 1), (95, 1), (135, 1), (141, 4), (142, 1), (144, 1), (154, 1)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>arrebentados</td>\n",
       "      <td>[(150, 1), (165, 1)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>dedo</td>\n",
       "      <td>[(29, 1), (109, 1), (215, 1)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>chefie</td>\n",
       "      <td>[(31, 1)]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "***"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rows = []\n",
    "columns = [\"word\",\"doc_id:freq\"]\n",
    "for word in inverted_index:\n",
    "    row = [word, inverted_index[word]]\n",
    "    rows.append(row)\n",
    "\n",
    "index_df = pd.DataFrame(rows, columns=columns)\n",
    "display(Markdown(\"***\"))\n",
    "display(Markdown(\"### Resulting Inverted Index\"))\n",
    "display(HTML(index_df.sample(15).to_html(index=False)))\n",
    "display(Markdown(\"***\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_df.to_csv(\"../output/inverted_index.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieval Approaches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Document At A Time Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_by_doc(index, query, k):\n",
    "    try:\n",
    "        import Queue as Q  # ver. < 3.0\n",
    "    except ImportError:\n",
    "        import queue as Q\n",
    "\n",
    "    result = []\n",
    "    q = Q.PriorityQueue()\n",
    "    L = index.loc[lambda df: df.word.isin(query)]\n",
    "\n",
    "    all_docs = set(index[\"doc_id:freq\"].\\\n",
    "                   apply(lambda pairs: list(doc_id for doc_id, freq in pairs)).sum())\n",
    "    \n",
    "    base_documents = L[\"doc_id:freq\"].sum()\n",
    "    \n",
    "    for doc in all_docs:\n",
    "        score = base_documents\n",
    "        \n",
    "        if score == 0:\n",
    "            pass\n",
    "        \n",
    "        elif score == []:\n",
    "            score = 0\n",
    "        else:\n",
    "            score = [fq for d_id, fq in score if d_id == doc]\n",
    "            if score != []:\n",
    "                score = reduce(lambda a,b : a+b,score)\n",
    "            else:\n",
    "                score = 0\n",
    "                \n",
    "        q.put(((-1) * score,doc))\n",
    "    \n",
    "    i = 0\n",
    "    while not q.empty() and i < k:\n",
    "        pair = q.get()\n",
    "        pair = ((-1) *pair[0],pair[1])\n",
    "        result.append(pair)\n",
    "        i += 1\n",
    "        \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Term At A Time Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_by_term(index, query, k):\n",
    "    try:\n",
    "        import Queue as Q  # ver. < 3.0\n",
    "    except ImportError:\n",
    "        import queue as Q\n",
    "\n",
    "    A = {}\n",
    "    result = []\n",
    "    R = Q.PriorityQueue()\n",
    "    q = Q.PriorityQueue()\n",
    "    L = index.loc[lambda df: df.word.isin(query)]\n",
    "    \n",
    "    if not L.empty: \n",
    "        for doc_id, freq in L[\"doc_id:freq\"].sum():\n",
    "            if doc_id not in A:\n",
    "                A[doc_id] = 0\n",
    "\n",
    "            A[doc_id] += freq\n",
    "\n",
    "        for doc_id, score in A.items():\n",
    "            q.put(((-1) * score,doc_id))    \n",
    "\n",
    "        i = 0\n",
    "        while not q.empty() and i < k:\n",
    "            pair = q.get()\n",
    "            pair = ((-1) *pair[0],pair[1])\n",
    "            result.append(pair)\n",
    "            i += 1\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Placing some queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's place 5 queries to each algorithm (with k = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries_df = pd.DataFrame([\"juíza\",\"Instagram\",\"reprodução\",\"real\",\"hostil\"],columns=[\"word\"])\n",
    "queries_df[\"word\"] = queries_df[\"word\"].apply(lambda x: [x])\n",
    "queries_df[\"by_doc\"] = queries_df[\"word\"].apply(lambda w: retrieve_by_doc(index_df, w, k))\n",
    "queries_df[\"by_term\"] = queries_df[\"word\"].apply(lambda w: retrieve_by_term(index_df, w, k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "***"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### Result by Algorithm"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>word</th>\n",
       "      <th>by_doc</th>\n",
       "      <th>by_term</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>[juíza]</td>\n",
       "      <td>[(2, 0), (1, 1), (0, 2), (0, 3), (0, 4), (0, 5), (0, 6), (0, 7), (0, 8), (0, 9)]</td>\n",
       "      <td>[(2, 0), (1, 1)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>[Instagram]</td>\n",
       "      <td>[(1, 85), (1, 110), (1, 151), (1, 229), (1, 242), (0, 0), (0, 1), (0, 2), (0, 3), (0, 4)]</td>\n",
       "      <td>[(1, 85), (1, 110), (1, 151), (1, 229), (1, 242)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>[reprodução]</td>\n",
       "      <td>[(2, 160), (1, 88), (1, 123), (1, 140), (1, 196), (0, 0), (0, 1), (0, 2), (0, 3), (0, 4)]</td>\n",
       "      <td>[(2, 160), (1, 88), (1, 123), (1, 140), (1, 196)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>[real]</td>\n",
       "      <td>[(3, 213), (2, 30), (2, 85), (2, 137), (2, 188), (1, 18), (1, 25), (1, 27), (1, 36), (1, 40)]</td>\n",
       "      <td>[(3, 213), (2, 30), (2, 85), (2, 137), (2, 188), (1, 18), (1, 25), (1, 27), (1, 36), (1, 40)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>[hostil]</td>\n",
       "      <td>[(1, 94), (1, 216), (0, 0), (0, 1), (0, 2), (0, 3), (0, 4), (0, 5), (0, 6), (0, 7)]</td>\n",
       "      <td>[(1, 94), (1, 216)]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "***"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.set_option('max_colwidth', -1)\n",
    "display(Markdown(\"***\"))\n",
    "display(Markdown(\"### Result by Algorithm\"))\n",
    "display(HTML(queries_df.to_html(index=False)))\n",
    "display(Markdown(\"***\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Is the implementation correct?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing the results of both algorithms for each *single term query* side by side we can see that results are consistent regarding:\n",
    "* Documents indexed by query words: \n",
    "    + The results are an exact match for both algorithms (see the results for the word **real**)\n",
    "* Documents not indexed by query words:\n",
    "    + Are retrievied by the algorithm **by_doc** with zero score and fill the result when not enough documents indexed by query words are found.\n",
    "    + Are not retrieved by the algorithm **by_term**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To further provide evidence let's manually check the score for the *single term query* **juíza**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>doc_id:freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7127</th>\n",
       "      <td>criativo</td>\n",
       "      <td>[(35, 2), (150, 1)]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          word          doc_id:freq\n",
       "7127  criativo  [(35, 2), (150, 1)]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_df.loc[index_df['word'] == 'criativo']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the dataframe we see that there are only two documents that contain the word \"criativo\":\n",
    "\n",
    "* The approach 'retrieve by document' iterates over all documents so the documents that don't contain \"criativo\" at all would be retrieved with 0 score.\n",
    "\n",
    "* The approach 'retrieve by document' only iterates over the documents that contain the term so the documents that don't contain it would be ignored\n",
    "\n",
    "Taking the aforementioned in account this would give us something like (sorted by score):\n",
    "\n",
    "* retrieve by document: [(2,35),(1,150),(0, doc_id1), (0, doc_id2) ...]\n",
    "       + where we would have as many documents with 0 score as necessary to reach the parameter *k*\n",
    "       \n",
    "* retrieve by document: [(2,35),(1,150)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "##### So, for k = 2 we should have identical results:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "###### (we should see *[(2,35),(1,150)]* for both)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retrieve by term, k=2: [(2, 35), (1, 150)]\n",
      "retrieve by doc, k=2: [(2, 35), (1, 150)]\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "##### So, for k = 5:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "###### (we should see three docs with 0 score only for *by document*)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retrieve by term, k=2: [(2, 35), (1, 150)]\n",
      "retrieve by doc, k=2: [(2, 35), (1, 150), (0, 0), (0, 1), (0, 2)]\n"
     ]
    }
   ],
   "source": [
    "display(Markdown(\"##### So, for k = 2 we should have identical results:\"))\n",
    "display(Markdown(\"###### (we should see *[(2,35),(1,150)]* for both)\"))\n",
    "print(\"retrieve by term, k=2: {}\".format(retrieve_by_term(index_df, [\"criativo\"], 2)))\n",
    "print(\"retrieve by doc, k=2: {}\".format(retrieve_by_doc(index_df, [\"criativo\"], 2)))\n",
    "\n",
    "display(Markdown(\"##### So, for k = 5:\"))\n",
    "display(Markdown(\"###### (we should see three docs with 0 score only for *by document*)\"))\n",
    "print(\"retrieve by term, k=2: {}\".format(retrieve_by_term(index_df, [\"criativo\"], 5)))\n",
    "print(\"retrieve by doc, k=2: {}\".format(retrieve_by_doc(index_df, [\"criativo\"], 5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison in terms of time and memory "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ast import literal_eval\n",
    "\n",
    "df = pd.read_csv(\"../output/inverted_index.csv\")\n",
    "df[\"doc_id:freq\"] = df[\"doc_id:freq\"].apply(lambda x: list(literal_eval(x)))\n",
    "\n",
    "all_words = list(df[\"word\"].values)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
